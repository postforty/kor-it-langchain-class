import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

from langchain_core.tools import tool
from datetime import datetime
from zoneinfo import ZoneInfo, ZoneInfoNotFoundError

import os
from dotenv import load_dotenv
load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")

# print("ë„êµ¬ í˜¸ì¶œ ê°€ëŠ¥í•œ ì±—ë´‡")

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", google_api_key=gemini_api_key)

# ë„êµ¬ í•¨ìˆ˜ ì •ì˜


@tool
def get_current_time(timezone: str, location: str) -> str:
    """ í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        timezone (str): íƒ€ì„ì¡´ (ì˜ˆ: 'Asia/Seoul') ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ€ì„ì¡´ì´ì–´ì•¼ í•¨
        location (str): ì§€ì—­ëª…. íƒ€ì„ì¡´ì´ ëª¨ë“  ì§€ëª…ì— ëŒ€ì‘ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì´í›„ llm ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ë¨
    """
    try:
        target_timezone = ZoneInfo(timezone)
        now = datetime.now(target_timezone).strftime("%Y-%m-%d %H:%M:%S")
        location_and_local_time = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now} ' # íƒ€ì„ì¡´, ì§€ì—­ëª…, í˜„ì¬ì‹œê°ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜
        print(location_and_local_time)
        return location_and_local_time
    except ZoneInfoNotFoundError:
        return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"


# ë„êµ¬ ë°”ì¸ë”©
tools = [get_current_time]
tool_dict = {"get_current_time": get_current_time}

llm_with_tools = llm.bind_tools(tools)


# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages):
    response = llm_with_tools.stream(messages)

    gathered = None
    for chunk in response:
        yield chunk

        if gathered is None:
            gathered = chunk
        else:
            gathered += chunk

    if gathered.tool_calls:
        st.session_state.messages.append(gathered)

        for tool_call in gathered.tool_calls:
            selected_tool = tool_dict[tool_call['name']]
            tool_msg = selected_tool.invoke(tool_call)
            print(tool_msg, type(tool_msg))
            st.session_state.messages.append(tool_msg)

        for chunk in get_ai_response(st.session_state.messages):
            yield chunk


# Streamlit ì•±
st.title("ğŸ’¬ Langchain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë´‡ì´ë‹¤. "),
        AIMessage("ë¬´ì—‡ì„ ë„ì™€ ë“œë¦´ê¹Œìš”?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, ToolMessage):
            st.chat_message("tool").write(msg.content)


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt))  # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    response = get_ai_response(st.session_state["messages"])

    result = st.chat_message("assistant").write_stream(response)  # AI ë©”ì‹œì§€ ì¶œë ¥
    st.session_state["messages"].append(AIMessage(result))  # AI ë©”ì‹œì§€ ì €ì¥

# ì§ˆë¬¸ ì˜ˆì‹œ:
# ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?"
# í…ŒìŠ¬ë¼ëŠ” í•œë‹¬ ì „ì— ë¹„í•´ ì£¼ê°€ê°€ ì˜¬ëë‚˜ ë‚´ë ¸ë‚˜?