import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from langchain_core.tools import tool
from datetime import datetime
from zoneinfo import ZoneInfo, ZoneInfoNotFoundError

import os
from dotenv import load_dotenv
load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")

# print("ë„êµ¬ í˜¸ì¶œ ê°€ëŠ¥í•œ ì±—ë´‡")

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", google_api_key=gemini_api_key)

# ë„êµ¬ í•¨ìˆ˜ ì •ì˜


@tool
def get_current_time(timezone: str, location: str) -> str:
    """ í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        timezone (str): íƒ€ì„ì¡´ (ì˜ˆ: 'Asia/Seoul') ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ€ì„ì¡´ì´ì–´ì•¼ í•¨
        location (str): ì§€ì—­ëª…. íƒ€ì„ì¡´ì´ ëª¨ë“  ì§€ëª…ì— ëŒ€ì‘ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì´í›„ llm ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ë¨
    """
    try:
        target_timezone = ZoneInfo(timezone)
        now = datetime.now(target_timezone).strftime("%Y-%m-%d %H:%M:%S")
        location_and_local_time = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now} ' # íƒ€ì„ì¡´, ì§€ì—­ëª…, í˜„ì¬ì‹œê°ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜
        print(location_and_local_time)
        return location_and_local_time
    except ZoneInfoNotFoundError:
        return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"


# ë„êµ¬ ë°”ì¸ë”©
tools = [get_current_time]

# ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ì •ì˜
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤."),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder("agent_scratchpad"),
])

# ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰ê¸° ì´ˆê¸°í™”
agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages):
    # ChatPromptTemplateì˜ inputê³¼ chat_historyì— ë§ê²Œ ë©”ì‹œì§€ ë¶„ë¦¬
    current_question = messages[-1].content
    chat_history = messages[:-1]

    full_response = ""
    for chunk in agent_executor.stream({"input": current_question, "chat_history": chat_history}):
        if "output" in chunk:
            full_response += chunk["output"]
            yield chunk["output"]
        elif "actions" in chunk:
            # ì—ì´ì „íŠ¸ê°€ ë„êµ¬ë¥¼ ì‹¤í–‰í•  ë•Œì˜ ì¤‘ê°„ ë‹¨ê³„ ì²˜ë¦¬
            for action in chunk["actions"]:
                tool_call_message = f"**ë„êµ¬ í˜¸ì¶œ:** `{action.tool}` (ì…ë ¥: `{action.tool_input}`)\n"
                yield tool_call_message
        elif "steps" in chunk:
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ ë‹¨ê³„ (ë„êµ¬ ì¶œë ¥ í¬í•¨)
            for step in chunk["steps"]:
                if hasattr(step, 'observation'):
                    tool_output_message = f"**ë„êµ¬ ì¶œë ¥:** `{step.observation}`\n"
                    yield tool_output_message
    
    # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… ì‘ë‹µ ì €ì¥
    st.session_state.messages.append(AIMessage(full_response))


# Streamlit ì•±
st.title("ğŸ’¬ Langchain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë´‡ì´ë‹¤. "),
        AIMessage("ë¬´ì—‡ì„ ë„ì™€ ë“œë¦´ê¹Œìš”?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, ToolMessage):
            st.chat_message("tool").write(msg.content)


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt))  # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    response = get_ai_response(st.session_state["messages"])

    result = st.chat_message("assistant").write_stream(response)  # AI ë©”ì‹œì§€ ì¶œë ¥

# ì§ˆë¬¸ ì˜ˆì‹œ:
# ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?
# í…ŒìŠ¬ë¼ëŠ” í•œë‹¬ ì „ì— ë¹„í•´ ì£¼ê°€ê°€ ì˜¬ëë‚˜ ë‚´ë ¸ë‚˜?