# ë­ì²´ì¸ ë©”ëª¨ë¦¬ ì—†ì´ ë©€í‹°í„´ ë§Œë“¤ê¸°
# ëŒ€í™” ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬
# ëŒ€í™” ë‚´ìš©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥, íˆìŠ¤í† ë¦¬ ìˆ˜ì •ì‹œ ìœ ìš©
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

import os
from dotenv import load_dotenv
load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", google_api_key=gemini_api_key)

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages):
    response = llm.stream(messages)

    for chunk in response:
        yield chunk


# Streamlit ì•±
st.title("ğŸ’¬ Langchain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë´‡ì´ë‹¤. "),
        AIMessage("How can I help you?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt))  # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    response = get_ai_response(st.session_state["messages"])

    result = st.chat_message("assistant").write_stream(response)  # AI ë©”ì‹œì§€ ì¶œë ¥
    st.session_state["messages"].append(AIMessage(result))  # AI ë©”ì‹œì§€ ì €ì¥
