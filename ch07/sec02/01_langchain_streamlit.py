from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_google_genai import ChatGoogleGenerativeAI
import streamlit as st

import os
from dotenv import load_dotenv
load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")


llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", google_api_key=gemini_api_key)

# print(llm.invoke([HumanMessage("ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?")]))
# print(llm.invoke([HumanMessage("í…ŒìŠ¬ë¼ëŠ” í•œë‹¬ ì „ì— ë¹„í•´ ì£¼ê°€ê°€ ì˜¬ëë‚˜ ë‚´ë ¸ë‚˜?")]))

st.title("ğŸ’¬ Langchain Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆì´ ë‹µí•˜ëŠ” AIì±—ë´‡ì´ë‹¤.")
    ]

# ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ëŒ€ì‹  session_state ì‚¬ìš©
if "store" not in st.session_state:
    st.session_state["store"] = {}


def get_session_history(session_id: str):
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = InMemoryChatMessageHistory()
    return st.session_state["store"][session_id]


with_message_history = RunnableWithMessageHistory(llm, get_session_history)

config = {"configurable": {"session_id": "abc2"}}

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)

if prompt := st.chat_input():
    print('user:', prompt)
    st.session_state.messages.append(HumanMessage(prompt))
    st.chat_message("user").write(prompt)

    response = with_message_history.stream(
        [HumanMessage(prompt)], config=config)

    ai_response_bucket = None
    with st.chat_message("assistant").empty():
        for r in response:
            if ai_response_bucket is None:
                ai_response_bucket = r
            else:
                ai_response_bucket += r
            print(r.content, end='')
            st.markdown(ai_response_bucket.content)

    msg = ai_response_bucket.content
    st.session_state.messages.append(ai_response_bucket)
    print('assistant:', msg)

# ì‹¤í–‰ ë°©ë²•
# streamlit run langchain_simple_chat_streamlit.py
# ì¢…ë£Œ ë°©ë²•
# ctrl + c
