{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090fd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    # temperature=0.0, # 창의성 (0.0 ~ 2.0)\n",
    "    temperature=0.1, # 창의성 (0.0 ~ 2.0)\n",
    "    # temperature=0.2, # 창의성 (0.0 ~ 2.0)\n",
    "    google_api_key=gemini_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840bbf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 **서울**입니다.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"대한민국의 수도는?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "471f5b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 한국말 할 수 있습니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(\"한국말 할 수 있어?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07efadb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='네, 한국말 할 수 있습니다. 어떻게 도와드릴까요?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--6e2554dd-1caf-445b-b23f-0e04bdc4b0f9-0', usage_metadata={'input_tokens': 7, 'output_tokens': 41, 'total_tokens': 48, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 28}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08aaa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 한국말 할 수 있습니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce84ef95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.5-flash',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71ddcf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 7,\n",
       " 'output_tokens': 41,\n",
       " 'total_tokens': 48,\n",
       " 'input_token_details': {'cache_read': 0},\n",
       " 'output_token_details': {'reasoning': 28}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb7985",
   "metadata": {},
   "source": [
    "### stream() 함수로 스트리밍 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a39ab53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream(\"Langchain에 대해 쉽게 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51299293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"랭체인(Langchain)은 한마디로 **'똑똑한 인공지능(LLM)을 활용해서 복잡한 일을 처리하게 도와주는 만능 도구 상자'**라고 생각하시면 됩니다.\\n\\n---\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7cf8f332-df99-4b6e-aa32-f5b2b9c06cda', usage_metadata={'input_tokens': 10, 'output_tokens': 1731, 'total_tokens': 1741, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1680}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(response) # 응답은 제너레이터임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33ac2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**비유를 들어 설명해 볼까요?**\n",
      "\n",
      "당신이 아주 똑똑한 **'천재 요리사' (LLM - Large Language Model)**를 고용했다고 상상해 보세요.\n",
      "이 요리사는 요리에 대한 지식은 엄청나고, 어떤 재료로 어떤 요리를 만들면 좋을지 기가 막히게 아이디어를 내고, 레시피를 설명하는 데는 최고입니다.\n",
      "\n",
      "하지만 이 요리사는 직접 장을 보거나, 레시피를 검색하거나, 불을 켜는 등의 **'실행'은 못합니다.** 그냥 머릿속으로만 생각하고 말로만 지시할 수 있죠.\n",
      "\n",
      "이때 필요한 것이 바로 **'유능한 주방 보조' (Langchain)**입니다.\n",
      "\n",
      "주방 보조는 천재 요리사의 지시를 받아서:\n",
      "*   필요한 재료가 뭔지 **인터넷으로 검색**하고 (외부 데이터 연동)\n",
      "*   냉장고에 재료가 있는지 **확인**하고 (내부 데이터 연동)\n",
      "*   부족하면 **마트에 가서 사 오고** (외부 도구 사용)\n",
      "*   레시피를 찾아서 **요리 순서를 정리**하고 (체인)\n",
      "*   요리사에게 \"어떤 요리를 할까요?\"라고 **물어보고 판단**해서 (에이전트)\n",
      "*   요리사가 요리에만 집중할 수 있도록 **모든 준비와 실행을 도와줍니다.**\n",
      "\n",
      "덕분에 천재 요리사는 오직 '요리 아이디어'와 '맛을 내는 핵심'에만 집중할 수 있게 되죠.\n",
      "\n",
      "---\n",
      "\n",
      "**랭체인의 주요 구성 요소 (주방 보조의 능력) 쉽게 설명:**\n",
      "\n",
      "1.  **LLM (Large Language Model):**\n",
      "    *   **천재 요리사:** 모든 지식과 아이디어를 가진 핵심 두뇌. (예: ChatGPT 같은 AI 모델)\n",
      "\n",
      "2.  **프롬프트 (Prompt):**\n",
      "    *   **요리사에게 주는 지시:** \"오늘 저녁은 매콤한 파스타로 부탁해!\" 처럼 LLM에게 어떤 작업을 할지 알려주는 질문이나 명령.\n",
      "\n",
      "3.  **체인 (Chains):**\n",
      "    *   **요리 순서:** \"재료 준비 -> 면 삶기 -> 소스 만들기 -> 플레이팅\" 처럼 여러 단계를 순서대로 연결해서 하나의 복잡한 작업을 처리하게 만듭니다.\n",
      "\n",
      "4.  **에이전트 (Agents):**\n",
      "    *   **똑똑한 판단자:** \"손님이 파스타를 원하네? 그럼 냉장고에 있는 재료를 확인하고, 부족하면 마트에 가서 사 와야겠어. 레시피는 인터넷에서 찾아볼까?\" 처럼, 주어진 목표를 달성하기 위해 **어떤 도구를 어떤 순서로 사용할지 스스로 판단하고 결정**하는 능력입니다.\n",
      "\n",
      "5.  **도구 (Tools):**\n",
      "    *   **주방 도구 & 외부 정보:** 칼, 냄비, 인터넷 검색 (레시피), 냉장고 (재료 확인), 마트 (재료 구매) 등 LLM이 외부 세상과 상호작용하고 정보를 얻거나 행동을 할 수 있게 해주는 기능들입니다. (예: 웹 검색, 계산기, 데이터베이스 조회 등)\n",
      "\n",
      "6.  **메모리 (Memory):**\n",
      "    *   **기억력:** \"지난번에 이 손님은 해산물을 싫어했지? 이번엔 고기로 만들어야겠다.\" 처럼, 이전 대화 내용을 기억하고 다음 대화에 활용하여 더 자연스럽고 연속적인 상호작용을 가능하게 합니다.\n",
      "\n",
      "---\n",
      "\n",
      "**결론적으로 랭체인은:**\n",
      "\n",
      "LLM이 혼자 할 수 없는 **복잡한 작업**을 수행하고, LLM을 **외부 데이터나 서비스와 연결**하며, 여러 단계를 **효율적으로 자동화**할 수 있도록 돕는 프레임워크입니다.\n",
      "\n",
      "마치 LLM에게 팔다리와 눈, 귀를 달아주는 것과 같아서, 단순한 질문 답변을 넘어 실제 세상의 문제들을 해결하는 강력한 인공지능 애플리케이션을 만들 수 있도록 돕는 역할을 합니다."
     ]
    }
   ],
   "source": [
    "for token in response:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
