{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3efa3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4bcebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='{language} 할 수 있어?')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"{language} 할 수 있어?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16d2b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.1, # 창의성 (0.0 ~ 2.0)\n",
    "    google_api_key=gemini_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183b47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a22cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='네, 한국말 할 수 있습니다. 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--8acd3373-3f8b-4c19-a010-d05eb9316623-0', usage_metadata={'input_tokens': 7, 'output_tokens': 45, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 31}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"language\": \"한국말\"}\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f916b",
   "metadata": {},
   "source": [
    "### 스트리밍 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6779cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"{topic}에 대해 쉽게 설명해줘?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bec038d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"topic\": \"LangChain\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ae191dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8796386",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.stream(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='LangChain은 쉽게 말해 **\"똑똑한 뇌(LLM)에게 손발과 기억력, 그리고 계획 능력을 달아주는 프레임워크\"** 라고 생각하시면 됩니다.\\n\\n조금 더 자세히', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--48ba9809-4dd5-427e-a70a-27778a37a4a3', usage_metadata={'input_tokens': 10, 'output_tokens': 1861, 'total_tokens': 1871, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1813}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain에 대해 쉽게 설명해 드릴게요! 🤖🛠️\n",
      "\n",
      "---\n",
      "\n",
      "**LangChain, 쉽게 말해볼까요?**\n",
      "\n",
      "LLM(Large Language Model, 거대 언어 모델)은 정말 똑똑한 '뇌'라고 생각하시면 돼요. 질문에 답하고, 글을 쓰고, 요약하는 등 언어와 관련된 일은 기가 막히게 잘하죠.\n",
      "\n",
      "그런데 이 똑똑한 뇌도 혼자서는 할 수 없는 일들이 있어요. 예를 들면:\n",
      "*   \"지금 날씨가 어때?\" 라고 물었을 때, LLM은 날씨 정보를 '알고' 있는 게 아니라, '날씨 정보가 필요하다'는 걸 이해할 뿐이에요. 실제로 인터넷에 접속해서 날씨를 검색할 수는 없죠.\n",
      "*   \"내 이메일에서 중요한 내용만 요약해 줘\" 라고 했을 때, LLM은 내 이메일 계정에 접속해서 내용을 가져올 수 없어요.\n",
      "*   \"이 문서 내용을 바탕으로 보고서를 써줘\" 라고 했을 때, LLM은 문서를 읽고 요약하는 건 잘하지만, 그 내용을 바탕으로 복잡한 구조의 보고서를 '단계별로' 작성하는 건 어려울 수 있어요.\n",
      "\n",
      "**여기서 LangChain이 등장합니다!**\n",
      "\n",
      "LangChain은 이 똑똑한 LLM '뇌'에 **'손발'을 달아주고, '기억력'을 주고, '복잡한 일 처리 능력'을 부여해서 훨씬 더 유용하고 강력한 인공지능 애플리케이션을 만들 수 있게 도와주는 '도구 상자' 또는 '비서' 같은 존재예요.**\n",
      "\n",
      "---\n",
      "\n",
      "**LangChain이 하는 일 (핵심 기능):**\n",
      "\n",
      "1.  **도구 (Tools) 🛠️:**\n",
      "    *   LLM이 외부 세상과 상호작용할 수 있게 해주는 기능이에요.\n",
      "    *   **예시:** 인터넷 검색 도구, 계산기 도구, 데이터베이스 조회 도구, 특정 API 호출 도구 등.\n",
      "    *   이제 LLM은 \"지금 날씨가 어때?\"라는 질문을 받으면, LangChain이 제공하는 '인터넷 검색 도구'를 사용해서 실제 날씨 정보를 찾아올 수 있게 되는 거죠!\n",
      "\n",
      "2.  **체인 (Chains) 🔗:**\n",
      "    *   여러 단계를 연결해서 하나의 큰 작업을 수행하게 해주는 기능이에요. 마치 레시피처럼요.\n",
      "    *   **예시:**\n",
      "        *   \"질문 받기\" → \"인터넷 검색\" → \"검색 결과 요약\" → \"요약된 내용으로 답변 생성\"\n",
      "        *   \"문서 읽기\" → \"핵심 내용 추출\" → \"추출된 내용으로 보고서 초안 작성\"\n",
      "    *   이렇게 여러 단계를 순서대로 처리해서 복잡한 작업을 해낼 수 있어요.\n",
      "\n",
      "3.  **에이전트 (Agents) 🕵️‍♂️:**\n",
      "    *   가장 똑똑한 기능 중 하나! LLM이 스스로 어떤 도구를 언제 사용할지 판단하게 하는 기능이에요.\n",
      "    *   **예시:**\n",
      "        *   사용자가 \"어제 뉴욕 증시가 어땠어? 그리고 그게 내 포트폴리오에 어떤 영향을 줄까?\" 라고 물으면,\n",
      "        *   에이전트는 LLM의 판단에 따라 먼저 '인터넷 검색 도구'로 뉴욕 증시를 검색하고,\n",
      "        *   그다음 '계산기 도구'나 '데이터 분석 도구'를 사용해서 포트폴리오 영향을 분석한 후,\n",
      "        *   최종 답변을 생성하는 식이죠.\n",
      "    *   마치 똑똑한 비서가 상황에 맞춰 알아서 필요한 도구를 꺼내 쓰는 것과 같아요.\n",
      "\n",
      "4.  **메모리 (Memory) 🧠:**\n",
      "    *   이전 대화 내용을 기억해서 맥락을 유지하게 해주는 기능이에요.\n",
      "    *   **예시:** 챗봇과 대화할 때, 이전에 했던 말을 기억하고 다음 대화에 반영하는 것이죠. \"아까 말했던 그 주제에 대해 더 알려줘\"라고 했을 때, '그 주제'가 무엇인지 기억하는 거예요.\n",
      "\n",
      "---\n",
      "\n",
      "**결론적으로, LangChain은 LLM을 활용해서 훨씬 더 똑똑하고 유용하며 복잡한 인공지능 애플리케이션을 만들 수 있도록 도와주는 '프레임워크' 또는 '도구 모음'이라고 생각하시면 됩니다.**\n",
      "\n",
      "LLM의 잠재력을 최대한 끌어내주는 다리 역할! 🌉"
     ]
    }
   ],
   "source": [
    "for token in response:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
