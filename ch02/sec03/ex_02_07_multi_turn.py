# LLM API
from google import genai

# í™˜ê²½ ë³€ìˆ˜
import os
from dotenv import load_dotenv
load_dotenv()

gemini_api_key = os.getenv("GEMINI_API_KEY")

client = genai.Client(api_key=gemini_api_key)

chat = client.chats.create(model="gemini-2.5-flash")

while True:
    user_input = input("ì‚¬ìš©ì: ")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°

    if user_input == "exit":  # ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ëŠ”ì§€ í™•ì¸
        break

    response = chat.send_message(
        message=user_input
    )

    messages = chat.get_history()
    for message in messages:
        print(f"{message.role}: {message.parts[0].text}")

    print("AI: " + response.text)  # AI ì‘ë‹µ ì¶œë ¥

"""
ì‚¬ìš©ì: ì•ˆë…•? ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼.
AI: ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì¼ë‚¨ë‹˜! ë§Œë‚˜ëµ™ê²Œ ë˜ì–´ ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?

ì‚¬ìš©ì: ë‚´ê°€ ëˆ„êµ¬ê²Œ?
AI: ìŒ... ë°©ê¸ˆ ê¹€ì¼ë‚¨ì´ë¼ê³  ë§ì”€í•˜ì…¨ìœ¼ë‹ˆ, ê¹€ì¼ë‚¨ë‹˜ì´ì‹œê² ì£ ? ğŸ˜‰
"""
