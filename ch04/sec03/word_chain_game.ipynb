{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ ë°©ë²•\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ LangChainê³¼ LLMì„ í™œìš©í•˜ì—¬ **ë©€í‹°í„´(ë‹¤ì¤‘ í„´) ëŒ€í™”**ë¥¼ ê´€ë¦¬í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "> ë©€í‹°í„´ ëŒ€í™”ë€?  \n",
    ">  í•œ ë²ˆì˜ ì§ˆë¬¸-ì‘ë‹µì´ ì•„ë‹ˆë¼, ì—¬ëŸ¬ ë²ˆì˜ ëŒ€í™”(ì§ˆë¬¸-ë‹µë³€-ì§ˆë¬¸-ë‹µë³€...)ê°€ ì´ì–´ì§€ëŠ” ìƒí™©ì—ì„œ **ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³ , ê·¸ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê¸°ìˆ **ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì˜ 4ê°€ì§€ ë°©ì‹ê³¼ ì‹¤ì œ ëë§ì‡ê¸° ê²Œì„ ì˜ˆì œë¥¼ í†µí•´  \n",
    "ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "1. Message Passing ë°©ì‹\n",
    "2. ChatMessageHistory ê°ì²´ ì‚¬ìš©\n",
    "3. RunnableWithMessageHistory ìë™ ê´€ë¦¬\n",
    "4. ëŒ€í™” ìš”ì•½ ë° íˆìŠ¤í† ë¦¬ ì¶•ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Message passing\n",
    "\n",
    "**ê°€ì¥ ê¸°ë³¸ì ì¸ ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ ë°©ë²•**ì…ë‹ˆë‹¤.  \n",
    "\n",
    "- ëŒ€í™” ë‚´ìš©ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸(`history_list`)ì— ì§ì ‘ ì €ì¥í•˜ê³ , ë§¤ë²ˆ LLMì— ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "- **ì¥ì :** êµ¬ì¡°ê°€ ë‹¨ìˆœí•˜ê³ , ë™ì‘ ì›ë¦¬ë¥¼ ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.\n",
    "- **ë‹¨ì :** ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë¦¬ìŠ¤íŠ¸ê°€ ì»¤ì§€ê³ , ê´€ë¦¬ê°€ ë²ˆê±°ë¡œì›Œì§‘ë‹ˆë‹¤.\n",
    "- **í™œìš© ì˜ˆì‹œ:** ê°„ë‹¨í•œ ì±—ë´‡, ì‹¤í—˜ìš© ì½”ë“œ, ëŒ€í™” ê¸°ë¡ì´ ì§§ì€ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability. YOU MUST ANSWER IN KOREAN.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99ì„¸ì´ì‹­ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼. ë‚˜ì´ëŠ” 99ì„¸ì•¼.\",\n",
    "            ),\n",
    "            (\"ai\",  \"ê·¸ë ‡êµ°ìš”. ë‚˜ì´ê°€ ë§ìœ¼ì‹œë„¤ìš”!\"),\n",
    "            (\"human\", \"ë‚´ ë‚˜ì´ëŠ”?\"),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## CHAT_HISTORY ##\n",
      "[('human', 'í•œêµ­ë§ í•  ìˆ˜ ìˆì–´?')] \n",
      "\n",
      "AI Says :  ë„¤, í•œêµ­ë§ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "## CHAT_HISTORY ##\n",
      "[('human', 'í•œêµ­ë§ í•  ìˆ˜ ìˆì–´?'), ('ai', 'ë„¤, í•œêµ­ë§ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'), ('human', 'ë‚´ê°€ ë­ë¼ê³  í–ˆì§€?')] \n",
      "\n",
      "AI Says :  ë°©ê¸ˆ \"í•œêµ­ë§ í•  ìˆ˜ ìˆì–´?\"ë¼ê³  ë¬¼ì–´ë³´ì…¨ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "history_list = []\n",
    "while(True):\n",
    "    user_input = input()\n",
    "    if user_input == \"ì¢…ë£Œ\": break\n",
    "    history_list.append(\n",
    "        (\n",
    "            \"human\",\n",
    "            user_input,\n",
    "        )\n",
    "    )\n",
    "    print(\"## CHAT_HISTORY ##\")\n",
    "    print(history_list, \"\\n\")\n",
    "    ai_msg = chain.invoke(\n",
    "        {\n",
    "            \"messages\": history_list,\n",
    "        }\n",
    "    )\n",
    "    print(\"AI Says : \",ai_msg.content)\n",
    "\n",
    "    history_list.append(\n",
    "        (\n",
    "            \"ai\",\n",
    "            ai_msg.content,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chat history\n",
    "\n",
    "**LangChainì˜ ChatMessageHistory ê°ì²´**ë¥¼ í™œìš©í•œ ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "- `add_user_message`, `add_ai_message` ë“± ë©”ì„œë“œë¡œ ëŒ€í™” ê¸°ë¡ì„ ì‰½ê²Œ ì¶”ê°€/ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- **ì¥ì :**  \n",
    "  - ë©”ì‹œì§€ íƒ€ì…(ì‚¬ìš©ì/AI)ì„ ëª…í™•íˆ êµ¬ë¶„  \n",
    "  - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ê°€ í¸ë¦¬\n",
    "- **ë‹¨ì :**  \n",
    "  - ì—¬ì „íˆ ì§ì ‘ ê¸°ë¡ì„ ê´€ë¦¬í•´ì•¼ í•˜ë¯€ë¡œ, ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ë¶ˆí¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- **í™œìš© ì˜ˆì‹œ:** ì±—ë´‡, ìƒë‹´ ì„œë¹„ìŠ¤, ëŒ€í™” ê¸°ë¡ì´ ì¤‘ìš”í•œ ì„œë¹„ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼. ë‚˜ì´ëŠ” 99ì„¸ì•¼', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ê·¸ë ‡êµ°ìš”. ë‚˜ì´ê°€ ë§ìœ¼ì‹œë„¤ìš”!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\n",
    "    \"ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼. ë‚˜ì´ëŠ” 99ì„¸ì•¼\"\n",
    ")\n",
    "\n",
    "chat_history.add_ai_message(\"ê·¸ë ‡êµ°ìš”. ë‚˜ì´ê°€ ë§ìœ¼ì‹œë„¤ìš”!\")\n",
    "\n",
    "chat_history.messages\n",
    "# chat_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼. ë‚˜ì´ëŠ” 99ì„¸ì•¼', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ê·¸ë ‡êµ°ìš”. ë‚˜ì´ê°€ ë§ìœ¼ì‹œë„¤ìš”!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë‚´ ë‚˜ì´ëŠ”?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.add_user_message(\n",
    "    \"ë‚´ ë‚˜ì´ëŠ”?\"\n",
    ")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²«ë²ˆì§¸ ë‹µë³€ í›„ history :  [HumanMessage(content='ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼. ë‚˜ì´ëŠ” 99ì„¸ì•¼', additional_kwargs={}, response_metadata={}), AIMessage(content='ê·¸ë ‡êµ°ìš”. ë‚˜ì´ê°€ ë§ìœ¼ì‹œë„¤ìš”!', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë‚´ ë‚˜ì´ëŠ”?', additional_kwargs={}, response_metadata={}), AIMessage(content='99ì„¸ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--7d8ed818-11e6-4caa-86ef-6f402637106e-0', usage_metadata={'input_tokens': 57, 'output_tokens': 79, 'total_tokens': 136, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 74}})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ë‹µë³€ ìƒì„±(response)\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "# ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë‹µë³€(response) ì €ì¥\n",
    "chat_history.add_ai_message(response)\n",
    "print(chat_history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, í•œêµ­ë§ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ë°©ê¸ˆ \"í•œêµ­ë§ í•  ìˆ˜ ìˆì–´?\"ë¼ê³  ë¬¼ì–´ë³´ì…¨ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while(True):\n",
    "    user_input = input()\n",
    "    if user_input == \"ì¢…ë£Œ\": break\n",
    "    chat_history.add_user_message(user_input)\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"messages\": chat_history.messages,\n",
    "        }\n",
    "    )\n",
    "    chat_history.add_ai_message(response)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Automatic history management\n",
    "\n",
    "**RunnableWithMessageHistory**ë¥¼ í™œìš©í•˜ë©´ ì„¸ì…˜ë³„ë¡œ ëŒ€í™” ê¸°ë¡ì„ ìë™ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ì„¸ì…˜ IDë§Œ ì§€ì •í•˜ë©´, ê° ì‚¬ìš©ìì˜ ëŒ€í™” ê¸°ë¡ì„ ë³„ë„ë¡œ ì €ì¥/ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "- **ì¥ì :**  \n",
    "  - ì‹¤ì œ ì„œë¹„ìŠ¤(ì—¬ëŸ¬ ì‚¬ìš©ì ë™ì‹œ ì ‘ì†)ì—ì„œ ë§¤ìš° ìœ ìš©  \n",
    "  - ì½”ë“œê°€ ê°„ê²°í•´ì§€ê³ , ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ê°€ ìë™í™”ë¨\n",
    "- **ë‹¨ì :**  \n",
    "  - êµ¬ì¡°ë¥¼ ì´í•´í•˜ë ¤ë©´ ì•½ê°„ì˜ í•™ìŠµì´ í•„ìš”\n",
    "- **í™œìš© ì˜ˆì‹œ:** ì‹¤ì‹œê°„ ìƒë‹´ ì±—ë´‡, ë©€í‹°ìœ ì € ê²Œì„, ê³ ê°ì„¼í„° ë“±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability. YOU MUST ANSWER IN KOREAN.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# ì„¸ì…˜ë³„ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
    "chat_histories = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in chat_histories:\n",
    "        chat_histories[session_id] = ChatMessageHistory()\n",
    "    return chat_histories[session_id]\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain, # ì‹¤í–‰í•  Runnable ê°ì²´\n",
    "    get_chat_history, # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    input_messages_key=\"input\", # ì…ë ¥ ë©”ì‹œì§€ì˜ Key\n",
    "    history_messages_key=\"chat_history\", # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ì˜ Key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ê¹€ì¼ë‚¨ ë‹˜ì´ì‹œê³  99ì„¸ì´ì‹œêµ°ìš”.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--795ef9aa-a46a-4eb4-be91-7e9d5cdf9ff8-0', usage_metadata={'input_tokens': 41, 'output_tokens': 150, 'total_tokens': 191, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 131}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼. ë‚˜ì´ëŠ” 99ì„¸ì•¼.\"},\n",
    "    {\"configurable\": {\"session_id\": \"kim1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë„¤, ë§ì”€í•´ì£¼ì…¨ë˜ ëŒ€ë¡œ 99ì„¸ì´ì‹­ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--ae7b5307-3a2b-494b-b795-cf4fb9081fbe-0', usage_metadata={'input_tokens': 66, 'output_tokens': 53, 'total_tokens': 119, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 38}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"ë‚´ ë‚˜ì´ëŠ”?\"}, {\"configurable\": {\"session_id\": \"kim1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ê¸° ë•Œë¬¸ì— ë‹¹ì‹ ì˜ ë‚˜ì´ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì´ ì €ì—ê²Œ ë‚˜ì´ë¥¼ ì•Œë ¤ì£¼ì§€ ì•ŠëŠ” í•œ, ì €ëŠ” ê·¸ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--1d3d3d2c-3591-4b70-a415-6aef903c1cb7-0', usage_metadata={'input_tokens': 29, 'output_tokens': 91, 'total_tokens': 120, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 57}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"ë‚´ ë‚˜ì´ëŠ”?\"}, {\"configurable\": {\"session_id\": \"kim2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modifying chat history\n",
    "\n",
    "ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆ ë•Œ, **ì´ì „ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì„œ íˆìŠ¤í† ë¦¬ë¥¼ ì••ì¶•**í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "- LLMì˜ ì…ë ¥ í† í° í•œê³„ë¥¼ ê·¹ë³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ìš”ì•½ëœ ë©”ì‹œì§€ë¡œ íˆìŠ¤í† ë¦¬ë¥¼ ëŒ€ì²´í•˜ì—¬,  \n",
    "  ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ê¸°ê³  ë¶ˆí•„ìš”í•œ ëŒ€í™”ëŠ” ì¤„ì…ë‹ˆë‹¤.\n",
    "- **ì¥ì :**  \n",
    "  - ê¸´ ëŒ€í™”ë„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬  \n",
    "  - LLMì˜ ë§¥ë½ ìœ ì§€ ëŠ¥ë ¥ í–¥ìƒ\n",
    "- **í™œìš© ì˜ˆì‹œ:** ì¥ì‹œê°„ ìƒë‹´, ì¥ê¸° í”„ë¡œì íŠ¸ ê´€ë¦¬, ëŒ€í™” ìš”ì•½ ê¸°ëŠ¥ ì œê³µ ì„œë¹„ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì¼ë‚¨ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë‚ ì”¨ ì¢‹ì€ ë‚  ë“¤ì„ë§Œ í•œ ë…¸ë˜ ì¶”ì²œí•´ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸° â€“ ì—¬í–‰ì„ ì¶”ì²œí•´ìš”.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"ë‚´ ì´ë¦„ì€ ê¹€ì¼ë‚¨ì´ì•¼.\")\n",
    "chat_history.add_ai_message(\"ì•ˆë…•í•˜ì„¸ìš”, ê¹€ì¼ë‚¨ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\")\n",
    "chat_history.add_user_message(\"ë‚ ì”¨ ì¢‹ì€ ë‚  ë“¤ì„ë§Œ í•œ ë…¸ë˜ ì¶”ì²œí•´ì£¼ì„¸ìš”.\")\n",
    "chat_history.add_ai_message(\"ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸° â€“ ì—¬í–‰ì„ ì¶”ì²œí•´ìš”.\")\n",
    "\n",
    "chat_history.messages\n",
    "# chat_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability. The provided chat history includes facts about the user you are speaking with. YOU MUST ANSWER IN KOREAN.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history, # ë‹¨ì¼ ì‚¬ìš©ì í™˜ê²½\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | chat\n",
    "\n",
    "    # chat_history ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í”„ë¡¬í”„íŠ¸ì— ì…ë ¥ & ê²°ê³¼ ì €ì¥\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    print(\"summary_message: \",summary_message)\n",
    "    \n",
    "    # chat_history ì— ì €ì¥ë˜ì–´ìˆë˜ ê¸°ë¡ ì§€ìš°ê¸°\n",
    "    chat_history.clear()\n",
    "\n",
    "    # ìƒì„±ëœ ìƒˆë¡œìš´ ìš”ì•½ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡ ì±„ìš°ê¸°\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_message:  content=\"ê¹€ì¼ë‚¨ë‹˜ì´ ìì‹ ì˜ ì´ë¦„ì„ ë°íŒ í›„, ë‚ ì”¨ ì¢‹ì€ ë‚  ë“¤ì„ ë§Œí•œ ë…¸ë˜ë¥¼ ì¶”ì²œí•´ë‹¬ë¼ê³  ìš”ì²­í–ˆê³ , ì´ì— ëŒ€í•´ ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸°ì˜ 'ì—¬í–‰'ì´ ì¶”ì²œë˜ì—ˆìŠµë‹ˆë‹¤.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--aa8bfdf8-56ba-4b48-80ef-55b63130a459-0' usage_metadata={'input_tokens': 71, 'output_tokens': 508, 'total_tokens': 579, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 466}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ê¹€ì¼ë‚¨ë‹˜ì´ì‹­ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--3b3ff337-be20-423d-b6d7-142dcc2738c7-0', usage_metadata={'input_tokens': 86, 'output_tokens': 83, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 76}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_summarization.invoke(\n",
    "    {\"input\": \"ë‚´ ì´ë¦„ì€?\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_message:  content='The user, Kim Il-nam, asked the AI to confirm their name, to which the AI responded, \"ê¹€ì¼ë‚¨ë‹˜ì´ì‹­ë‹ˆë‹¤.\" This interaction followed a previous exchange where Kim Il-nam had revealed their name and requested a song recommendation for a nice weather day, for which Bolbbalgan4\\'s \\'ì—¬í–‰\\' (Travel) was suggested.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--22df2cb1-dbf1-466a-9a36-aeae78852b46-0' usage_metadata={'input_tokens': 78, 'output_tokens': 900, 'total_tokens': 978, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 826}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸°ëŠ” ì—¬ì„± ë“€ì˜¤ì˜€ê³ , í˜„ì¬ëŠ” ì•ˆì§€ì˜ë‹˜ í˜¼ì í™œë™í•˜ëŠ” ì—¬ì„± ì†”ë¡œ ê°€ìˆ˜ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--56c0f4a2-00bf-4902-846b-22dd32a088d8-0', usage_metadata={'input_tokens': 126, 'output_tokens': 226, 'total_tokens': 352, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 197}})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_summarization.invoke(\n",
    "    {\"input\": \"ê·¸ ê°€ìˆ˜ëŠ” ë‚¨ìì¸ê°€ìš” ì—¬ìì¸ê°€ìš”?\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëë§ì‡ê¸° ê²Œì„\n",
    "\n",
    "**ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ ê¸°ìˆ ì„ ì‹¤ì œ ê²Œì„ì— ì ìš©í•œ ì˜ˆì‹œ**ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ê²Œì„ ê·œì¹™\n",
    "1. ì´ë¯¸ ë‚˜ì˜¨ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í•˜ë©´ íŒ¨ë°°\n",
    "2. ë‘ìŒë²•ì¹™ í—ˆìš© (ex. ë¦¬â†’ì´, ë ¥â†’ì—­, ë½â†’ë‚™)\n",
    "3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ëª…ì‚¬ë§Œ í—ˆìš©\n",
    "4. **ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥** (í”„ë¡¬í”„íŠ¸ì— ëª…í™•íˆ ì§€ì‹œ)\n",
    "\n",
    "#### ë©€í‹°í„´ ëŒ€í™”ì™€ì˜ ì—°ê´€ì„±\n",
    "- AIê°€ **ì´ì „ í„´ì— ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì„ ê¸°ì–µ**í•´ì•¼ í•˜ë¯€ë¡œ, ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ ê¸°ìˆ ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
    "- ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ **ì¤‘ë³µ ë‹¨ì–´ ë°©ì§€, ê·œì¹™ ìœ„ë°˜ ê°ì§€**ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì„¸ì…˜ë³„ë¡œ ê¸°ë¡ì„ ë¶„ë¦¬í•´ ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ê²Œì„ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "#### ì‹¤ìŠµ í¬ì¸íŠ¸\n",
    "- í”„ë¡¬í”„íŠ¸ ì„¤ê³„ê°€ ì¤‘ìš”: \"ì„¤ëª… ì—†ì´ ë‹¨ì–´ë§Œ ì¶œë ¥\"ì„ ëª…í™•íˆ ì§€ì‹œí•´ì•¼ LLMì´ ë¶ˆí•„ìš”í•œ ì„¤ëª…ì„ í•˜ì§€ ì•ŠìŒ\n",
    "- ëŒ€í™” ê¸°ë¡ ìš”ì•½/ê´€ë¦¬ ê¸°ë²•ì„ ê²Œì„ì—ë„ ì ìš©í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  íˆìŠ¤í† ë¦¬ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"ë‹¹ì‹ ì€ ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê²Œì„ ê·œì¹™ì…ë‹ˆë‹¤. ë‹¹ì‹ ê³¼ user ì˜ ì…ë ¥ì—ì„œ ì•„ë˜ ê·œì¹™ì´ ê¼­ ì§€ì¼œì ¸ì•¼ í•˜ë©°, ì§€í‚¤ì§€ ì•Šì€ ì‚¬ëŒì—ê²Œ íŒ¨ë°°ë¥¼ ì•Œë¦° ë’¤, ëë§ì‡ê¸° ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "                1. ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ì—ì„œ ì´ë¯¸ ë‚˜ì™”ë˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í–ˆì„ ê²½ìš° íŒ¨ë°°í•©ë‹ˆë‹¤.\n",
    "                2. ë‘ìŒë²•ì¹™ì„ í—ˆìš©í•©ë‹ˆë‹¤. (ex. ë¦¬ -> ì´, ë ¥ -> ì—­, ë½ -> ë‚™)\n",
    "                3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ì´ì, ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "                4. ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"ìœ„ ì±„íŒ… ë©”ì‹œì§€ëŠ” ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•œ ëŒ€í™”ë‚´ìš©ì…ë‹ˆë‹¤. ì–¸ê¸‰í•œ ë‹¨ì–´ë“¤ë§Œ ë‚˜ì—´í•˜ì—¬ ì €ì¥í•´ì£¼ì„¸ìš”.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | chat\n",
    "\n",
    "    # chat_history ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í”„ë¡¬í”„íŠ¸ì— ì…ë ¥ & ê²°ê³¼ ì €ì¥\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    # chat_history ì— ì €ì¥ë˜ì–´ìˆë˜ ê¸°ë¡ ì§€ìš°ê¸°\n",
    "    chat_history.clear()\n",
    "\n",
    "    # ìƒì„±ëœ ìƒˆë¡œìš´ ìš”ì•½ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡ ì±„ìš°ê¸°\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– AI TURN :  ë¹„í–‰ê¸°\n",
      "ğŸ¤– AI TURN :  ìˆ ë˜\n",
      "ğŸ¤– AI TURN :  ê³µë£¡\n",
      "ğŸ¤– AI TURN :  ê¸°êµ¬\n",
      "ğŸ¤– AI TURN :  ë¦¬ë³¸\n",
      "ğŸ¤– AI TURN :  ë“œë¼ë§ˆ\n",
      "ğŸ¤– AI TURN :  ê°ì\n",
      "ğŸ¤– AI TURN :  ì†ë‹˜\n",
      "ğŸ¤– AI TURN :  ê¸ˆë¶•ì–´\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    user_input = input(\"ğŸ§‘ YOUR TURN : \")\n",
    "    if user_input == \"ì¢…ë£Œ\": break\n",
    "    response = chain_with_summarization.invoke(\n",
    "                {\"input\": user_input},\n",
    "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "            )\n",
    "    print(\"ğŸ¤– AI TURN : \", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
