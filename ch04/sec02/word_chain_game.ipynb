{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëë§ì‡ê¸° ê²Œì„\n",
    "\n",
    "**ë©€í‹°í„´** ëŒ€í™” ê´€ë¦¬ ê¸°ìˆ ì„ ì‹¤ì œ ê²Œì„ì— ì ìš©í•œ ì˜ˆì‹œ\n",
    "\n",
    "#### ê²Œì„ ê·œì¹™\n",
    "1. ì´ë¯¸ ë‚˜ì˜¨ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í•˜ë©´ íŒ¨ë°°\n",
    "2. ë‘ìŒë²•ì¹™ í—ˆìš© (ex. ë¦¬â†’ì´, ë ¥â†’ì—­, ë½â†’ë‚™)\n",
    "3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ëª…ì‚¬ë§Œ í—ˆìš©\n",
    "4. **ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥** (í”„ë¡¬í”„íŠ¸ì— ëª…í™•íˆ ì§€ì‹œ)\n",
    "\n",
    "#### ë©€í‹°í„´ ëŒ€í™”ì™€ì˜ ì—°ê´€ì„±\n",
    "- AIê°€ **ì´ì „ í„´ì— ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì„ ê¸°ì–µ**í•´ì•¼ í•˜ë¯€ë¡œ, ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ ê¸°ìˆ ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
    "- ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ **ì¤‘ë³µ ë‹¨ì–´ ë°©ì§€, ê·œì¹™ ìœ„ë°˜ ê°ì§€**ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì„¸ì…˜ë³„ë¡œ ê¸°ë¡ì„ ë¶„ë¦¬í•´ ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ê²Œì„ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "#### ì‹¤ìŠµ í¬ì¸íŠ¸\n",
    "- í”„ë¡¬í”„íŠ¸ ì„¤ê³„ê°€ ì¤‘ìš”: \"ì„¤ëª… ì—†ì´ ë‹¨ì–´ë§Œ ì¶œë ¥\"ì„ ëª…í™•íˆ ì§€ì‹œí•´ì•¼ LLMì´ ë¶ˆí•„ìš”í•œ ì„¤ëª…ì„ í•˜ì§€ ì•ŠìŒ\n",
    "- ëŒ€í™” ê¸°ë¡ ìš”ì•½/ê´€ë¦¬ ê¸°ë²•ì„ ê²Œì„ì—ë„ ì ìš©í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  íˆìŠ¤í† ë¦¬ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"ë‹¹ì‹ ì€ ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê²Œì„ ê·œì¹™ì…ë‹ˆë‹¤. ë‹¹ì‹ ê³¼ user ì˜ ì…ë ¥ì—ì„œ ì•„ë˜ ê·œì¹™ì´ ê¼­ ì§€ì¼œì ¸ì•¼ í•˜ë©°, ì§€í‚¤ì§€ ì•Šì€ ì‚¬ëŒì—ê²Œ íŒ¨ë°°ë¥¼ ì•Œë¦° ë’¤, ëë§ì‡ê¸° ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "                1. ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ì—ì„œ ì´ë¯¸ ë‚˜ì™”ë˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë§í–ˆì„ ê²½ìš° íŒ¨ë°°í•©ë‹ˆë‹¤.\n",
    "                2. ë‘ìŒë²•ì¹™ì„ í—ˆìš©í•©ë‹ˆë‹¤. (ex. ë¦¬ -> ì´, ë ¥ -> ì—­, ë½ -> ë‚™)\n",
    "                3. êµ­ì–´ì‚¬ì „ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ì´ì, ëª…ì‚¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "                4. ì•„ë¬´ëŸ° ì„¤ëª… ì—†ì´, ëë§ì‡ê¸° ë‹¨ì–´ë§Œ í•œê¸€ë¡œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"ìœ„ ì±„íŒ… ë©”ì‹œì§€ëŠ” ëë§ì‡ê¸° ê²Œì„ì„ ì§„í–‰í•œ ëŒ€í™”ë‚´ìš©ì…ë‹ˆë‹¤. ì–¸ê¸‰í•œ ë‹¨ì–´ë“¤ë§Œ ë‚˜ì—´í•˜ì—¬ ì €ì¥í•´ì£¼ì„¸ìš”.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | llm\n",
    "\n",
    "    # chat_history ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í”„ë¡¬í”„íŠ¸ì— ì…ë ¥ & ê²°ê³¼ ì €ì¥\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    # chat_history ì— ì €ì¥ë˜ì–´ìˆë˜ ê¸°ë¡ ì§€ìš°ê¸°\n",
    "    chat_history.clear()\n",
    "\n",
    "    # ìƒì„±ëœ ìƒˆë¡œìš´ ìš”ì•½ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡ ì±„ìš°ê¸°\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– AI TURN :  ë©´ë„\n",
      "ğŸ¤– AI TURN :  ë§ˆì°¨\n",
      "ğŸ¤– AI TURN :  ì§€ìš°ê°œ\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    user_input = input(\"ğŸ§‘ YOUR TURN : \")\n",
    "    if user_input == \"ì¢…ë£Œ\": break\n",
    "    response = chain_with_summarization.invoke(\n",
    "                {\"input\": user_input},\n",
    "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "            )\n",
    "    print(\"ğŸ¤– AI TURN : \", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
